{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from absl import logging as absl_logging\n",
    "absl_logging.set_verbosity(-10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by initializing ZenML in our directory. We are going to use a local stack to begin with, for simplicity and then transition to other stacks. This can be achieved in code by executing the following block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml init\n",
    "!zenml stack set local_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by looking at the definition of a pipeline that we want to build. This will give an overview of what we want to achieve and how we plan on getting there. We'll dive into the details on some of the interesting steps after that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Training Pipeline\n",
    "\n",
    "We will be using a simple MNIST image recognition problem to show how ZenML can help you build a complete solution which involves importing and processing data, training and evaluating your model and finally deploying the model if the data it trained on has not drifted. \n",
    "\n",
    "The code below shows how our pipeline for this example is designed. \n",
    "- First, the data gets loaded through the importer step.\n",
    "- We normalize it next and make it ready for training.\n",
    "- The next steps train and evaluate the model. \n",
    "- We then take the input dataset and pass it to Evidently to generate a report.\n",
    "- We use the drift detector step to figure out if drift has occured.\n",
    "- We pass this information to the model deployer and the discord bot to take the desired actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.pipelines import pipeline\n",
    "\n",
    "@pipeline(enable_cache=True, requirements_file=requirements_file)\n",
    "def continuous_deployment_pipeline(\n",
    "    importer,\n",
    "    normalizer,\n",
    "    trainer,\n",
    "    evaluator,\n",
    "    drift_splitter,\n",
    "    drift_detector,\n",
    "    deployment_trigger,\n",
    "    model_deployer,\n",
    "    discord_bot\n",
    "):\n",
    "    # Link all the steps' artifacts together\n",
    "    x_train, y_train, x_test, y_test = importer()\n",
    "    x_trained_normed, x_test_normed = normalizer(x_train=x_train, x_test=x_test)\n",
    "    \n",
    "    model = trainer(x_train=x_trained_normed, y_train=y_train)\n",
    "    accuracy = evaluator(x_test=x_test_normed, y_test=y_test, model=model)\n",
    "\n",
    "    reference_dataset, new_dataset = drift_splitter(x_train)\n",
    "    drift_report, _ = drift_detector(reference_dataset, new_dataset)\n",
    "    \n",
    "    deployment_decision = deployment_trigger(drift_report)\n",
    "    model_deployer(deployment_decision)\n",
    "    discord_bot(deployment_decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linking Steps with data\n",
    "\n",
    "Looking at the relations defined above, you can see that ZenML uses data to establish links between the steps and all the inputs and outputs (which we call artifacts) are beautifully persisted and made available to every step code by ZenML without you having to explicitly configure the boring stuff yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Composability\n",
    "\n",
    "You can get creative with the way you want your pipeline to work and ZenML enables you to seamlessly switch between different implementations of your steps. You can notice that all the step functions are taken as inputs to the pipeline function which means you won't have to change the pipeline code at all to implement new funcitonality! (like, when using a new importer for your data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's look at the Steps\n",
    "\n",
    "So far, you've seen the big picture when it comes to what we want to build. Now, let's dive into the steps to see the options that ZenML provides to build the logic into your execution flow. Let's start by looking at how we detect drift using Evidently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrating Evidently\n",
    "Evidently is an open source tool that allows you to easily compute drift on your data.\n",
    "\n",
    "At its core, Evidently’s drift detection calculation functions take in a reference data set and compare it with a separate comparison dataset. These are both passed in as Pandas dataframes, though CSV inputs are also possible. ZenML implements this functionality in the form of several standardized steps along with an easy way to use the visualization tools also provided along with Evidently as ‘Dashboards’.\n",
    "\n",
    "If you’re working on any kind of machine learning problem that has an ongoing training loop that takes in new data, you’ll want to guard against drift. Machine learning pipelines are built on top of data inputs, so it is worth checking for drift if you have a model that was trained on a certain distribution of data. The incoming data is something you have less control over and since things often change out in the real world, you should have a plan for knowing when things have shifted. Evidently offers a growing set of features that help you monitor not only data drift but other key aspects like target drift and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to install evidently to our python environment\n",
    "!zenml integration install evidently -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zenml provides some standard steps for the evidently integration\n",
    "from zenml.integrations.evidently.steps import (\n",
    "    EvidentlyProfileConfig,\n",
    "    EvidentlyProfileStep,\n",
    ")\n",
    "\n",
    "# We create a config object for our evidently step - \n",
    "#  here we choose the datadrift profile \n",
    "evidently_drift_detector_config = EvidentlyProfileConfig(\n",
    "    column_mapping=None,profile_sections=[\"datadrift\"],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data for drift detection\n",
    "\n",
    "We are using the MNIST dataset from Keras for training in this example. Since this is not a timeseries, one way of splittig the data could be to select an arbitary row and then take all samples prior to it as rhe reference dataset and the rows after it as the new data. \n",
    "\n",
    "We have the option to add noise to the dataset to control the occurence of drift. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Girl on car drifting awesome GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from steps.splitter import reference_data_splitter, TrainingSplitConfig\n",
    "\n",
    "drift_data_split_config = TrainingSplitConfig(\n",
    "    row=30000,\n",
    "    add_noise=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the model conditionally\n",
    "\n",
    "Pipelines in ZenML are flexible to allow incorporation of complex workflows like conditional execution of steps or parallel execution when the orchestrator allows it.\n",
    "In our example, we want to be able to deploy the model if there is no drift detected and to send a message on a Discord channel in case it is. \n",
    "\n",
    "We use the MLflow deployer step from our MLflow integration that takes a boolean value to conditionally deploy the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_deployer = mlflow_deployer_step(name=\"model_deployer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A deployment trigger function is defined which takes in the report from the Evidently drift detector step and returns True if there is drift in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.steps import step\n",
    "\n",
    "@step\n",
    "def deployment_trigger(\n",
    "    drift_report: dict,\n",
    ") -> bool:\n",
    "    \"\"\"Implements a simple model deployment trigger that looks at the\n",
    "    drift report and deploys if there's none\"\"\"\n",
    "\n",
    "    drift = drift_report[\"data_drift\"][\"data\"][\"metrics\"][\"dataset_drift\"]\n",
    "\n",
    "    if drift:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
