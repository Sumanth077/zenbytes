{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZenML: Open-source MLOps Framework for reproducible ML pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Test](../_assets/Logo/zenml.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Sam](../_assets/sam.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from absl import logging as absl_logging\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "absl_logging.set_verbosity(-10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by initializing ZenML in our directory. We are going to use a local stack to begin with, for simplicity and then transition to other stacks. This can be achieved in code by executing the following block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize ZenML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!zenml init\n",
    "!zenml stack set local_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by looking at the definition of a pipeline that we want to build. This will give an overview of what we want to achieve and how we plan on getting there. We'll dive into the details on some of the interesting steps after that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a simple training pipeline\n",
    "\n",
    "Create a mnist training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import ClassifierMixin\n",
    "\n",
    "from zenml.integrations.sklearn.helpers.digits import (\n",
    "    get_digits,\n",
    ")\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from zenml.pipelines import pipeline\n",
    "from zenml.steps import Output, step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Steps\n",
    "In the code that follows, you can see that we are defining the various steps of our pipeline. Each step is decorated with @step, the main abstraction that is currently available for creating pipeline steps.\n",
    "\n",
    "The first step is an import step that downloads the MNIST dataset and returns four numpy arrays as its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@step\n",
    "def importer() -> Output(\n",
    "    X_train=np.ndarray, X_test=np.ndarray, y_train=np.ndarray, y_test=np.ndarray\n",
    "):\n",
    "    \"\"\"Loads the digits array as normal numpy arrays.\"\"\"\n",
    "    X_train, X_test, y_train, y_test = get_digits()\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then add a Trainer step, that takes the imported data and trains a sklearn classifier on the data. Note that the model is not explicitly saved within the step. Under the hood ZenML uses Materializers to automatically persist the Artifacts that result from each step into the Artifact Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def svc_trainer(\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    ") -> ClassifierMixin:\n",
    "    \"\"\"Train another simple sklearn classifier for the digits dataset.\"\"\"\n",
    "    model = SVC(gamma=0.001)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we add an Evaluator step that takes as input the test set and the trained model and evaluates some final metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def evaluator(\n",
    "    X_test: np.ndarray,\n",
    "    y_test: np.ndarray,\n",
    "    model: ClassifierMixin,\n",
    ") -> float:\n",
    "    \"\"\"Calculate the accuracy on the test set\"\"\"\n",
    "    test_acc = model.score(X_test, y_test)\n",
    "    print(f\"Test accuracy: {test_acc}\")\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and Run Pipeline\n",
    "A pipeline is defined with the @pipeline decorator. This defines the various steps of the pipeline and specifies the dependencies between the steps, thereby determining the order in which they will be run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline\n",
    "def digits_pipeline(\n",
    "    importer,\n",
    "    trainer,\n",
    "    evaluator,\n",
    "):\n",
    "    \"\"\"Links all the steps together in a pipeline\"\"\"\n",
    "    X_train, X_test, y_train, y_test = importer()\n",
    "    model = trainer(X_train=X_train, y_train=y_train)\n",
    "    evaluator(X_test=X_test, y_test=y_test, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the pipeline\n",
    "first_pipeline = digits_pipeline(\n",
    "    importer=importer(),\n",
    "    trainer=svc_trainer(),\n",
    "    evaluator=evaluator(),\n",
    ")\n",
    "first_pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Drift Detection with Evidently\n",
    "\n",
    "Evidently is an open source tool that allows you to easily compute drift on your data. [Here](https://blog.zenml.io/zenml-loves-evidently/) is a little blog post of ours that explains the evidently integration in a bit more detail. \n",
    "\n",
    "At its core, Evidently’s drift detection calculation functions take in a reference data set and compare it with a separate comparison dataset. These are both passed in as Pandas dataframes, though CSV inputs are also possible. ZenML implements this functionality in the form of several standardized steps along with an easy way to use the visualization tools also provided along with Evidently as ‘Dashboards’.\n",
    "\n",
    "\n",
    "If you’re working on any kind of machine learning problem that has an ongoing training loop that takes in new data, you’ll want to guard against drift. Machine learning pipelines are built on top of data inputs, so it is worth checking for drift if you have a model that was trained on a certain distribution of data. The incoming data is something you have less control over and since things often change out in the real world, you should have a plan for knowing when things have shifted. Evidently offers a [growing set of features](https://github.com/evidentlyai/evidently) that help you monitor not only data drift but other key aspects like target drift and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Evidently](../_assets/zenml+evidently.png \"Evidently\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!zenml integration install evidently -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a Drift Detection Step to our Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.integrations.evidently.steps import (\n",
    "    EvidentlyProfileConfig,\n",
    "    EvidentlyProfileStep,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def get_reference_data(\n",
    "    X_train: np.ndarray,\n",
    "    X_test: np.ndarray,\n",
    ") -> Output(reference=pd.DataFrame, comparison=pd.DataFrame):\n",
    "    \"\"\"Splits data for drift detection.\"\"\"\n",
    "    # X_train = _add_awgn(X_train)\n",
    "    columns = [str(x) for x in list(range(X_train.shape[1]))]\n",
    "    return pd.DataFrame(X_test, columns=columns), pd.DataFrame(X_train, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline(enable_cache=False)\n",
    "def digits_pipeline_with_drift(\n",
    "    importer,\n",
    "    trainer,\n",
    "    evaluator,\n",
    "    \n",
    "    get_reference_data,\n",
    "    drift_detector,\n",
    "):\n",
    "    \"\"\"Links all the steps together in a pipeline\"\"\"\n",
    "    X_train, X_test, y_train, y_test = importer()\n",
    "    model = trainer(X_train=X_train, y_train=y_train)\n",
    "    evaluator(X_test=X_test, y_test=y_test, model=model)\n",
    "    \n",
    "    reference, comparison = get_reference_data(X_train, X_test)\n",
    "    drift_detector(reference, comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the pipeline with evidently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evidently_profile_config = EvidentlyProfileConfig(\n",
    "    column_mapping=None,\n",
    "    profile_sections=[\"datadrift\"])\n",
    "\n",
    "second_pipeline = digits_pipeline_with_drift(\n",
    "    importer=importer(),\n",
    "    trainer=svc_trainer(),\n",
    "    evaluator=evaluator(),\n",
    "    \n",
    "    # EvidentlyProfileStep takes reference_dataset and comparison dataset\n",
    "    get_reference_data=get_reference_data(),\n",
    "    drift_detector=EvidentlyProfileStep(config=evidently_profile_config)\n",
    ")\n",
    "second_pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from zenml.integrations.evidently.visualizers import EvidentlyVisualizer\n",
    "from zenml.repository import Repository\n",
    "import json\n",
    "\n",
    "repo = Repository()\n",
    "p = repo.get_pipeline('digits_pipeline_with_drift')\n",
    "last_run = p.runs[-1]\n",
    "\n",
    "drift_detection_step = last_run.get_step(\n",
    "    name=\"drift_detector\"\n",
    ")\n",
    "evidently_outputs = drift_detection_step\n",
    "\n",
    "EvidentlyVisualizer().visualize(evidently_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add alerts with Discord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Discord](../_assets/evidently+discord.png \"Discord\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from zenml.steps import step\n",
    "\n",
    "# This is a private ZenML Discord channel. We will get notified if you use \n",
    "# this, but you won't be able to see it. Feel free to create a new Discord \n",
    "# [webhook](https://support.discord.com/hc/en-us/articles/228383668-Intro-to-Webhooks) \n",
    "# and replace this one!\n",
    "DISCORD_URL = (\n",
    "    \"https://discord.com/api/webhooks/935835443826659339/Q32jTwmqc\"\n",
    "    \"GJAUr-r_J3ouO-zkNQPchJHqTuwJ7dK4wiFzawT2Gu97f6ACt58UKFCxEO9\"\n",
    ")\n",
    "\n",
    "\n",
    "@step(enable_cache=False)\n",
    "def discord_alert(\n",
    "    drift_report: dict\n",
    ") -> None:\n",
    "    \"\"\"Send a message to the discord channel to report drift.\n",
    "    Args:\n",
    "        deployment_decision: True if drift detected; false otherwise.\n",
    "    \"\"\"\n",
    "    drift = drift_report[\"data_drift\"][\"data\"][\"metrics\"][\"dataset_drift\"]\n",
    "    url = DISCORD_URL\n",
    "    data = {\n",
    "        \"content\": \"Drift Detected!\" if drift else \"No Drift Detected!\",\n",
    "        \"username\": \"Drift Bot\",\n",
    "    }\n",
    "    result = requests.post(url, json=data)\n",
    "\n",
    "    try:\n",
    "        result.raise_for_status()\n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        print(err)\n",
    "    else:\n",
    "        print(\n",
    "            \"Posted to discord successfully, code {}.\".format(\n",
    "                result.status_code\n",
    "            )\n",
    "        )\n",
    "    print(\"Drift detected\" if drift else \"No Drift detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the pipeline step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline\n",
    "def digits_pipeline_with_drift_alert(\n",
    "    importer,\n",
    "    trainer,\n",
    "    evaluator,\n",
    "    \n",
    "    get_reference_data,\n",
    "    drift_detector,\n",
    "    \n",
    "    alerter,\n",
    "):\n",
    "    \"\"\"Links all the steps together in a pipeline\"\"\"\n",
    "    X_train, X_test, y_train, y_test = importer()\n",
    "    model = trainer(X_train=X_train, y_train=y_train)\n",
    "    evaluator(X_test=X_test, y_test=y_test, model=model)\n",
    "    \n",
    "    reference, comparison = get_reference_data(X_train, X_test)\n",
    "    drift_report, _ = drift_detector(reference, comparison)\n",
    "    \n",
    "    alerter(drift_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evidently_profile_config = EvidentlyProfileConfig(\n",
    "    column_mapping=None,\n",
    "    profile_sections=[\"datadrift\"])\n",
    "\n",
    "third_pipeline = digits_pipeline_with_drift_alert(\n",
    "    importer=importer(),\n",
    "    trainer=svc_trainer(),\n",
    "    evaluator=evaluator(),\n",
    "    \n",
    "    # EvidentlyProfileStep takes reference_dataset and comparison dataset\n",
    "    get_reference_data=get_reference_data(),\n",
    "    drift_detector=EvidentlyProfileStep(config=evidently_profile_config),\n",
    "    \n",
    "    # Add discord\n",
    "    alerter=discord_alert()\n",
    ")\n",
    "third_pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track experiments and parameters with MLFlow\n",
    "\n",
    "For this pipeline we want to take you a step further by showing you some more integrations. We will be using MLFlow Tracking for visualizing and comparing multiple pipeline runs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MLflow](../_assets/evidently+discord+mlflow.png \"MLflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml integration install mlflow -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a trainer with mlflow logging\n",
    "\n",
    "Now that we have mlflow enabled we need to choose what we want to log into mlflow. For now, we have chosen to use the [mlflow autolog](https://www.mlflow.org/docs/latest/tracking.html#scikit-learn) functionality to automatically log the model and training parameters within the training step.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note:</b> The @enable_mlflow decorator above the step is all we need to get started with mlflow. This decorator sets up an mlflow experiment and an mlflow backend for all runs within this pipeline. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.integrations.mlflow.mlflow_step_decorator import enable_mlflow\n",
    "import mlflow\n",
    "\n",
    "\n",
    "@enable_mlflow\n",
    "@step(enable_cache=False)\n",
    "def svc_trainer_mlflow(\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    ") -> ClassifierMixin:\n",
    "    \"\"\"Train another simple sklearn classifier for the digits dataset.\"\"\"\n",
    "    mlflow.sklearn.autolog()\n",
    "    model = SVC(gamma=0.001)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourth_pipeline = digits_pipeline_with_drift_alert(\n",
    "    importer=importer(),\n",
    "    trainer=svc_trainer_mlflow(),\n",
    "    evaluator=evaluator(),\n",
    "    \n",
    "    # EvidentlyProfileStep takes reference_dataset and comparison dataset\n",
    "    get_reference_data=get_reference_data(),\n",
    "    drift_detector=EvidentlyProfileStep(config=evidently_profile_config),\n",
    "    \n",
    "    # Add discord\n",
    "    alerter=discord_alert()\n",
    ")\n",
    "fourth_pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's have a look at mlflow\n",
    "\n",
    "Training is done, let's have a look at our mlflow ui and see if our training including the model have made it in there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will start a serving process for mlflow \n",
    "#  - if you want to continue in the notebook you need to manually\n",
    "#  interrupt the kernel \n",
    "from zenml.environment import Environment\n",
    "from zenml.integrations.mlflow.mlflow_environment import MLFLOW_ENVIRONMENT_NAME\n",
    "\n",
    "!mlflow ui --backend-store-uri {Environment()[MLFLOW_ENVIRONMENT_NAME].tracking_uri} --port 4998\n",
    "\n",
    "Environment()[MLFLOW_ENVIRONMENT_NAME].tracking_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create another trainer with a different model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@enable_mlflow\n",
    "@step(enable_cache=False)\n",
    "def tree_trainer_with_mlflow(\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    ") -> ClassifierMixin:\n",
    "    \"\"\"Train another simple sklearn classifier for the digits dataset.\"\"\"\n",
    "    mlflow.sklearn.autolog()\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifth_pipeline = digits_pipeline_with_drift_alert(\n",
    "    importer=importer(),\n",
    "    trainer=tree_trainer_with_mlflow(),\n",
    "    evaluator=evaluator(),\n",
    "    \n",
    "    # EvidentlyProfileStep takes reference_dataset and comparison dataset\n",
    "    get_reference_data=get_reference_data(),\n",
    "    drift_detector=EvidentlyProfileStep(config=evidently_profile_config),\n",
    "    \n",
    "    # Add discord\n",
    "    alerter=discord_alert()\n",
    ")\n",
    "fifth_pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will start a serving process for mlflow \n",
    "#  - if you want to continue in the notebook you need to manually\n",
    "#  interrupt the kernel \n",
    "from zenml.environment import Environment\n",
    "from zenml.integrations.mlflow.mlflow_environment import MLFLOW_ENVIRONMENT_NAME\n",
    "\n",
    "!mlflow ui --backend-store-uri {Environment()[MLFLOW_ENVIRONMENT_NAME].tracking_uri} --port 4998"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continous Deployment using mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline(enable_cache=False)\n",
    "def continuous_deployment_pipeline(\n",
    "    importer,\n",
    "    trainer,\n",
    "    evaluator,\n",
    "    get_reference_data,\n",
    "    drift_detector,\n",
    "    alerter,\n",
    "    \n",
    "    deployment_trigger,\n",
    "    model_deployer,\n",
    "):\n",
    "    \"\"\"Links all the steps together in a pipeline\"\"\"\n",
    "    X_train, X_test, y_train, y_test = importer()\n",
    "    model = trainer(X_train=X_train, y_train=y_train)\n",
    "    evaluator(X_test=X_test, y_test=y_test, model=model)\n",
    "    \n",
    "    reference, comparison = get_reference_data(X_train, X_test)\n",
    "    drift_report, _ = drift_detector(reference, comparison)\n",
    "    \n",
    "    alerter(drift_report)\n",
    "    \n",
    "    # new \n",
    "    deployment_decision = deployment_trigger(drift_report)\n",
    "    model_deployer(deployment_decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def deployment_trigger(\n",
    "    drift_report: dict,\n",
    ") -> bool:\n",
    "    \"\"\"Implements a simple model deployment trigger that looks at the\n",
    "    drift report and deploys if there's none\"\"\"\n",
    "\n",
    "    drift = drift_report[\"data_drift\"][\"data\"][\"metrics\"][\"dataset_drift\"]\n",
    "\n",
    "    if drift:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from zenml.integrations.mlflow.steps import mlflow_deployer_step\n",
    "from zenml.services import load_last_service_from_step\n",
    "from zenml.integrations.mlflow.steps import MLFlowDeployerConfig\n",
    "\n",
    "model_deployer = mlflow_deployer_step(name=\"model_deployer\")\n",
    "\n",
    "\n",
    "sixth_pipeline = continuous_deployment_pipeline(\n",
    "    importer=importer(),\n",
    "    trainer=tree_trainer_with_mlflow(),\n",
    "    evaluator=evaluator(),\n",
    "    \n",
    "    # EvidentlyProfileStep takes reference_dataset and comparison dataset\n",
    "    get_reference_data=get_reference_data(),\n",
    "    drift_detector=EvidentlyProfileStep(config=evidently_profile_config),\n",
    "    \n",
    "    # Add discord\n",
    "    alerter=discord_alert(),\n",
    "    \n",
    "    deployment_trigger=deployment_trigger(),\n",
    "    model_deployer=model_deployer(config=MLFlowDeployerConfig(workers=1)),\n",
    ")\n",
    "sixth_pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = Repository()\n",
    "p = repo.get_pipeline('continuous_deployment_pipeline')\n",
    "last_run = p.runs[-1]\n",
    "X_test = last_run.steps[0].outputs['X_test'].read()\n",
    "y_test = last_run.steps[0].outputs['y_test'].read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = load_last_service_from_step(\n",
    "    pipeline_name=\"continuous_deployment_pipeline\",\n",
    "    step_name=\"model_deployer\",\n",
    "    running=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[0], y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "service.predict(X_test[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ax.set_axis_off()\n",
    "plt.imshow(X_test[0].reshape(8, 8), cmap=plt.cm.gray_r, interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
