{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZenML: Open-source MLOps Framework for reproducible ML pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Test](_assets/Logo/zenml.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from absl import logging as absl_logging\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "absl_logging.set_verbosity(-10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize ZenML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by initializing ZenML in our directory. We are going to use a local stack to begin with, for simplicity and then transition to other stacks. This can be achieved in code by executing the following block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\u001b[2;36mZenML repository initialized at \u001b[0m\u001b[2;35m/Users/strickvl/coding/zenml/repos/\u001b[0m\u001b[2;95mzenbytes.\u001b[0m\n",
      "\u001b[2;32m⠋\u001b[0m\u001b[2;36m \u001b[0m\u001b[2;36mInitializing ZenML repository at /Users/strickvl/coding/zenml/repos/zenbytes.\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠋\u001b[0m Initializing ZenML repository at /Users/strickvl/coding/zenml/repos/zenbytes.\n",
      "\n",
      "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[2;36mThe local active profile was initialized to \u001b[0m\u001b[2;32m'default'\u001b[0m\u001b[2;36m and the local active stack\u001b[0m\n",
      "\u001b[2;36mto \u001b[0m\u001b[2;32m'default'\u001b[0m\u001b[2;36m. This local configuration will only take effect when you're running\u001b[0m\n",
      "\u001b[2;36mZenML from the initialized repository root, or from a subdirectory. For more \u001b[0m\n",
      "\u001b[2;36minformation on profile and stack configuration, please visit \u001b[0m\n",
      "\u001b[2;4;94mhttps://docs.zenml.io.\u001b[0m\n",
      "\u001b[2;36mRunning with active profile: \u001b[0m\u001b[2;32m'default'\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;2;36m(\u001b[0m\u001b[2;36mlocal\u001b[0m\u001b[1;2;36m)\u001b[0m\n",
      "\u001b[?25l\u001b[2;36mActive stack set to: \u001b[0m\u001b[2;32m'default'\u001b[0m\n",
      "\u001b[2K\u001b[32m⠋\u001b[0m Setting the active stack to 'default'... to 'default'...\u001b[0m\n",
      "\u001b[1A\u001b[2K"
     ]
    }
   ],
   "source": [
    "!rm -rf .zen\n",
    "!zenml init\n",
    "!zenml stack set default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install integrations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZenML handles integrations natively, to avoid dependency conflicts, so make sure to use the following command to install the integrations required for this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml integration install sklearn dash evidently mlflow feast -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a simple training pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by looking at the definition of a pipeline that we want to build. This will give an overview of what we want to achieve and how we plan on getting there. We'll dive into the details on some of the interesting steps after that.\n",
    "\n",
    "![Pipeline1](_assets/chapter_1/first_pipeline.png \"Pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feast Alterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!redis-server --daemonize yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strickvl         38901   3.9  0.0 34415488   1720 s002  Ss+   2:45pm   0:00.01 /bin/zsh -c ps aux | grep redis-server\n",
      "strickvl         38897   0.2  0.0 35417268   2240   ??  Ss    2:45pm   0:00.02 redis-server *:6379  \n",
      "strickvl         38903   0.0  0.0 34263116    992 s002  S+    2:45pm   0:00.00 grep redis-server\n"
     ]
    }
   ],
   "source": [
    "!ps aux | grep redis-server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2;36mRunning with active profile: \u001b[0m\u001b[2;32m'default'\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;2;36m(\u001b[0m\u001b[2;36mlocal\u001b[0m\u001b[1;2;36m)\u001b[0m\n",
      "\u001b[1;35mRegistered stack component with type 'feature_store' and name 'feast_store'.\u001b[0m\n",
      "\u001b[2;36mSuccessfully registered feature store `feast_store`.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!zenml feature-store register feast_store -t feast --feast_repo=\"./feature_importer_repo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2;36mRunning with active profile: \u001b[0m\u001b[2;32m'default'\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;2;36m(\u001b[0m\u001b[2;36mlocal\u001b[0m\u001b[1;2;36m)\u001b[0m\n",
      "\u001b[?25l\u001b[32m⠋\u001b[0m Registering stack 'fs_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠙\u001b[0m Registering stack 'fs_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠹\u001b[0m Registering stack 'fs_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠸\u001b[0m Registering stack 'fs_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠼\u001b[0m Registering stack 'fs_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠦\u001b[0m Registering stack 'fs_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠇\u001b[0m Registering stack 'fs_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠏\u001b[0m Registering stack 'fs_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠋\u001b[0m Registering stack 'fs_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠙\u001b[0m Registering stack 'fs_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠹\u001b[0m Registering stack 'fs_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠸\u001b[0m Registering stack 'fs_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠼\u001b[0m Registering stack 'fs_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠴\u001b[0m Registering stack 'fs_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠧\u001b[0m Registering stack 'fs_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠇\u001b[0m Registering stack 'fs_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠏\u001b[0m Registering stack 'fs_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠋\u001b[0m Registering stack 'fs_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠙\u001b[0m Registering stack 'fs_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠹\u001b[0m Registering stack 'fs_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠼\u001b[0m Registering stack 'fs_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠴\u001b[0m Registering stack 'fs_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠦\u001b[0m Registering stack 'fs_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠧\u001b[0m Registering stack 'fs_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠇\u001b[0m Registering stack 'fs_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠏\u001b[0m Registering stack 'fs_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠋\u001b[0m Registering stack 'fs_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠹\u001b[0m Registering stack 'fs_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠸\u001b[0m Registering stack 'fs_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠼\u001b[0m Registering stack 'fs_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠴\u001b[0m Registering stack 'fs_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠦\u001b[0m Registering stack 'fs_stack'...\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠧\u001b[0m Registering stack 'fs_stack'...\n",
      "\u001b[1;35mRegistered stack with name 'fs_stack'.\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[2;36mStack \u001b[0m\u001b[2;32m'fs_stack'\u001b[0m\u001b[2;36m successfully registered!\u001b[0m\n",
      "\u001b[2;32m⠇\u001b[0m\u001b[2;36m \u001b[0m\u001b[2;36mRegistering stack 'fs_stack'...\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[32m⠇\u001b[0m Registering stack 'fs_stack'...\n",
      "\n",
      "\u001b[1A\u001b[2K\u001b[1A\u001b[2K"
     ]
    }
   ],
   "source": [
    "# register the sagemaker stack\n",
    "!zenml stack register fs_stack -m default -o default -a default -f feast_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2;36mRunning with active profile: \u001b[0m\u001b[2;32m'default'\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;2;36m(\u001b[0m\u001b[2;36mlocal\u001b[0m\u001b[1;2;36m)\u001b[0m\n",
      "\u001b[?25l\u001b[2;36mActive stack set to: \u001b[0m\u001b[2;32m'fs_stack'\u001b[0m\n",
      "\u001b[2K\u001b[32m⠋\u001b[0m Setting the active stack to 'fs_stack'...to 'fs_stack'...\u001b[0m\n",
      "\u001b[1A\u001b[2K"
     ]
    }
   ],
   "source": [
    "# activate the stack\n",
    "!zenml stack set fs_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2;36mRunning with active profile: \u001b[0m\u001b[2;32m'default'\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;2;36m(\u001b[0m\u001b[2;36mlocal\u001b[0m\u001b[1;2;36m)\u001b[0m\n",
      "\u001b[3m        Stack Configuration        \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mCOMPONENT_TYPE\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mCOMPONENT_NAME\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┠────────────────┼────────────────┨\n",
      "┃ ARTIFACT_STORE │ default        ┃\n",
      "┠────────────────┼────────────────┨\n",
      "┃ FEATURE_STORE  │ feast_store    ┃\n",
      "┠────────────────┼────────────────┨\n",
      "┃ METADATA_STORE │ default        ┃\n",
      "┠────────────────┼────────────────┨\n",
      "┃ ORCHESTRATOR   │ default        ┃\n",
      "┗━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━━━━━┛\n",
      "\u001b[2;3m     'fs_stack' stack (ACTIVE)     \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# view the current active stack\n",
    "!zenml stack describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import numpy as np\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.datasets import load_digits, load_iris, load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from numpy.typing import NDArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_digits() -> Tuple[\n",
    "    \"NDArray[np.float64]\",\n",
    "    \"NDArray[np.float64]\",\n",
    "    \"NDArray[np.int64]\",\n",
    "    \"NDArray[np.int64]\",\n",
    "]:\n",
    "    \"\"\"Returns the digits dataset in the form of a tuple of numpy\n",
    "    arrays.\"\"\"\n",
    "    digits = load_digits()\n",
    "    # flatten the images\n",
    "    n_samples = len(digits.images)\n",
    "    data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "    # Split data into 50% train and 50% test subsets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data, digits.target, test_size=0.5, shuffle=False\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭──────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/folders/49/7x17fsrn4knfk852z31cs_vm0000gn/T/ipykernel_36635/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">4107435704.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">line: 4&gt;</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/var/folders/49/7x17fsrn4knfk852z31cs_vm0000gn/T/ipykernel_36635/4107435704.py'</span>          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/strickvl/coding/zenml/repos/zenbytes/pyarrow/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">table.pxi</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1685</span> in                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">pyarrow.lib.Table.from_arrays</span>                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/Users/strickvl/coding/zenml/repos/zenbytes/pyarrow/table.pxi'</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/strickvl/coding/zenml/repos/zenbytes/pyarrow/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">table.pxi</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">615</span> in                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">pyarrow.lib._sanitize_arrays</span>                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/Users/strickvl/coding/zenml/repos/zenbytes/pyarrow/table.pxi'</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/strickvl/coding/zenml/repos/zenbytes/pyarrow/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">table.pxi</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">589</span> in                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">pyarrow.lib._schema_from_arrays</span>                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/Users/strickvl/coding/zenml/repos/zenbytes/pyarrow/table.pxi'</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰───────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>Length of names <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">)</span> does not match length of arrays <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">150</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m─────────────────────────── \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m ───────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/var/folders/49/7x17fsrn4knfk852z31cs_vm0000gn/T/ipykernel_36635/\u001b[0m\u001b[1;33m4107435704.py\u001b[0m:\u001b[94m4\u001b[0m in \u001b[92m<cell\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mline: 4>\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'/var/folders/49/7x17fsrn4knfk852z31cs_vm0000gn/T/ipykernel_36635/4107435704.py'\u001b[0m          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/strickvl/coding/zenml/repos/zenbytes/pyarrow/\u001b[0m\u001b[1;33mtable.pxi\u001b[0m:\u001b[94m1685\u001b[0m in                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mpyarrow.lib.Table.from_arrays\u001b[0m                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'/Users/strickvl/coding/zenml/repos/zenbytes/pyarrow/table.pxi'\u001b[0m                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/strickvl/coding/zenml/repos/zenbytes/pyarrow/\u001b[0m\u001b[1;33mtable.pxi\u001b[0m:\u001b[94m615\u001b[0m in                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mpyarrow.lib._sanitize_arrays\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'/Users/strickvl/coding/zenml/repos/zenbytes/pyarrow/table.pxi'\u001b[0m                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/strickvl/coding/zenml/repos/zenbytes/pyarrow/\u001b[0m\u001b[1;33mtable.pxi\u001b[0m:\u001b[94m589\u001b[0m in                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mpyarrow.lib._schema_from_arrays\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'/Users/strickvl/coding/zenml/repos/zenbytes/pyarrow/table.pxi'\u001b[0m                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰───────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mValueError: \u001b[0mLength of names \u001b[1m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m)\u001b[0m does not match length of arrays \u001b[1m(\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert all the iris data into a parquet file\n",
    "data = load_iris()['data']\n",
    "\n",
    "table = pa.Table.from_arrays(\n",
    "    data,\n",
    "    names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class'] # give names to each columns\n",
    ")\n",
    "\n",
    "table\n",
    "# Save it:\n",
    "pq.write_table(table, 'table.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv')\n",
    "iris.to_parquet(\"iris.pq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species\n",
       "0             5.1          3.5           1.4          0.2     setosa\n",
       "1             4.9          3.0           1.4          0.2     setosa\n",
       "2             4.7          3.2           1.3          0.2     setosa\n",
       "3             4.6          3.1           1.5          0.2     setosa\n",
       "4             5.0          3.6           1.4          0.2     setosa\n",
       "..            ...          ...           ...          ...        ...\n",
       "145           6.7          3.0           5.2          2.3  virginica\n",
       "146           6.3          2.5           5.0          1.9  virginica\n",
       "147           6.5          3.0           5.2          2.0  virginica\n",
       "148           6.2          3.4           5.4          2.3  virginica\n",
       "149           5.9          3.0           5.1          1.8  virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet('iris.pq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Feast\n",
    "\n",
    "- get the data from sklearn.datasets\n",
    "- convert it all to a parquet file / format\n",
    "\n",
    "\n",
    "- write the relevant code to ingest that where you define entities and featureviews\n",
    "- `feast apply` from within the feature_importer_repo to load the data\n",
    "- write / specify the entity_df and features that you'll pass in to the historical data store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Steps\n",
    "In the code that follows, you can see that we are defining the various steps of our pipeline. Each step is decorated with @step, the main abstraction that is currently available for creating pipeline steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import ClassifierMixin\n",
    "\n",
    "from zenml.integrations.sklearn.helpers.digits import (\n",
    "    get_digits,\n",
    ")\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from zenml.pipelines import pipeline\n",
    "from zenml.steps import Output, step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is an import step that downloads the DIGITS dataset and returns four numpy arrays as its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def importer() -> Output(\n",
    "    X_train=np.ndarray, X_test=np.ndarray, y_train=np.ndarray, y_test=np.ndarray\n",
    "):\n",
    "    \"\"\"Loads the digits array as normal numpy arrays.\"\"\"\n",
    "    X_train, X_test, y_train, y_test = get_digits()\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then add a Trainer step, that takes the imported data and trains a sklearn classifier on the data. Note that the model is not explicitly saved within the step. Under the hood ZenML uses Materializers to automatically persist the Artifacts that result from each step into the Artifact Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def svc_trainer(\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    ") -> ClassifierMixin:\n",
    "    \"\"\"Train another simple sklearn classifier for the digits dataset.\"\"\"\n",
    "    print(\"test\")\n",
    "    model = SVC(gamma=0.001)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we add an Evaluator step that takes as input the test set and the trained model and evaluates some final metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def evaluator(\n",
    "    X_test: np.ndarray,\n",
    "    y_test: np.ndarray,\n",
    "    model: ClassifierMixin,\n",
    ") -> float:\n",
    "    \"\"\"Calculate the accuracy on the test set\"\"\"\n",
    "    test_acc = model.score(X_test, y_test)\n",
    "    print(f\"Test accuracy: {test_acc}\")\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run and visualize Pipeline\n",
    "A pipeline is defined with the @pipeline decorator. This defines the various steps of the pipeline and specifies the dependencies between the steps, thereby determining the order in which they will be run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline\n",
    "def digits_pipeline(\n",
    "    importer,\n",
    "    trainer,\n",
    "    evaluator,\n",
    "):\n",
    "    \"\"\"Links all the steps together in a pipeline\"\"\"\n",
    "    X_train, X_test, y_train, y_test = importer()\n",
    "    model = trainer(X_train=X_train, y_train=y_train)\n",
    "    evaluator(X_test=X_test, y_test=y_test, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the pipeline\n",
    "first_pipeline = digits_pipeline(\n",
    "    importer=importer(),\n",
    "    trainer=svc_trainer(),\n",
    "    evaluator=evaluator(),\n",
    ")\n",
    "first_pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can again use the lineage visualizer to see what just happened. The integration will visualize the pipeline run for us right in the browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.integrations.dash.visualizers.pipeline_run_lineage_visualizer import (\n",
    "    PipelineRunLineageVisualizer,\n",
    ")\n",
    "from zenml.repository import Repository\n",
    "\n",
    "repo = Repository()\n",
    "pipelines = repo.get_pipelines()\n",
    "p = pipelines[-1]\n",
    "run = p.runs[-1]\n",
    "steps = run.steps\n",
    "s = steps[-1]\n",
    "PipelineRunLineageVisualizer().visualize(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Drift Detection with Evidently\n",
    "\n",
    "Evidently is an open source tool that allows you to easily compute drift on your data. [Here](https://blog.zenml.io/zenml-loves-evidently/) is a little blog post of ours that explains the evidently integration in a bit more detail. \n",
    "\n",
    "At its core, Evidently’s drift detection calculation functions take in a reference data set and compare it with a separate comparison dataset. These are both passed in as Pandas dataframes, though CSV inputs are also possible. ZenML implements this functionality in the form of several standardized steps along with an easy way to use the visualization tools also provided along with Evidently as ‘Dashboards’.\n",
    "\n",
    "\n",
    "If you’re working on any kind of machine learning problem that has an ongoing training loop that takes in new data, you’ll want to guard against drift. Machine learning pipelines are built on top of data inputs, so it is worth checking for drift if you have a model that was trained on a certain distribution of data. The incoming data is something you have less control over and since things often change out in the real world, you should have a plan for knowing when things have shifted. Evidently offers a [growing set of features](https://github.com/evidentlyai/evidently) that help you monitor not only data drift but other key aspects like target drift and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Evidently](_assets/zenml+evidently.png \"Evidently\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a new pipeline with drift detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Pipeline2](_assets/chapter_1/second_pipeline.png \"Pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline(enable_cache=False)\n",
    "def digits_pipeline_with_drift(\n",
    "    importer,\n",
    "    trainer,\n",
    "    evaluator,\n",
    "    \n",
    "    get_reference_data,\n",
    "    drift_detector,\n",
    "):\n",
    "    \"\"\"Links all the steps together in a pipeline\"\"\"\n",
    "    X_train, X_test, y_train, y_test = importer()\n",
    "    model = trainer(X_train=X_train, y_train=y_train)\n",
    "    evaluator(X_test=X_test, y_test=y_test, model=model)\n",
    "    \n",
    "    reference, comparison = get_reference_data(X_train, X_test)\n",
    "    drift_detector(reference, comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the standard evidently step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.integrations.evidently.steps import (\n",
    "    EvidentlyProfileConfig,\n",
    "    EvidentlyProfileStep,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def get_reference_data(\n",
    "    X_train: np.ndarray,\n",
    "    X_test: np.ndarray,\n",
    ") -> Output(reference=pd.DataFrame, comparison=pd.DataFrame):\n",
    "    \"\"\"Splits data for drift detection.\"\"\"\n",
    "    # X_train = _add_awgn(X_train)\n",
    "    columns = [str(x) for x in list(range(X_train.shape[1]))]\n",
    "    return pd.DataFrame(X_test, columns=columns), pd.DataFrame(X_train, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run and visualize the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evidently_profile_config = EvidentlyProfileConfig(\n",
    "    column_mapping=None,\n",
    "    profile_sections=[\"datadrift\"])\n",
    "\n",
    "second_pipeline = digits_pipeline_with_drift(\n",
    "    importer=importer(),\n",
    "    trainer=svc_trainer(),\n",
    "    evaluator=evaluator(),\n",
    "    \n",
    "    # EvidentlyProfileStep takes reference_dataset and comparison dataset\n",
    "    get_reference_data=get_reference_data(),\n",
    "    drift_detector=EvidentlyProfileStep(config=evidently_profile_config)\n",
    ")\n",
    "second_pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.integrations.evidently.visualizers import EvidentlyVisualizer\n",
    "from zenml.repository import Repository\n",
    "import json\n",
    "\n",
    "repo = Repository()\n",
    "p = repo.get_pipeline('digits_pipeline_with_drift')\n",
    "last_run = p.runs[-1]\n",
    "\n",
    "drift_detection_step = last_run.get_step(\n",
    "    name=\"drift_detector\"\n",
    ")\n",
    "evidently_outputs = drift_detection_step\n",
    "\n",
    "EvidentlyVisualizer().visualize(evidently_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add alerts with Discord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLOps promotes giving more visibility to your team about runs of pipelines. A good way to do that is to add a ChatOps step to your pipeline to ping some relevant results every time the pipeline is run. You can use a Discord webhook in your step for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Discord](_assets/evidently+discord.png \"Discord\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an alerter step in your pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Pipeline3](_assets/chapter_1/third_pipeline.png \"Pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@pipeline\n",
    "def digits_pipeline_with_drift_alert(\n",
    "    importer,\n",
    "    trainer,\n",
    "    evaluator,\n",
    "    \n",
    "    get_reference_data,\n",
    "    drift_detector,\n",
    "    \n",
    "    alerter,\n",
    "):\n",
    "    \"\"\"Links all the steps together in a pipeline\"\"\"\n",
    "    X_train, X_test, y_train, y_test = importer()\n",
    "    model = trainer(X_train=X_train, y_train=y_train)\n",
    "    evaluator(X_test=X_test, y_test=y_test, model=model)\n",
    "    \n",
    "    reference, comparison = get_reference_data(X_train, X_test)\n",
    "    drift_report, _ = drift_detector(reference, comparison)\n",
    "    \n",
    "    alerter(drift_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a discord alerter step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from zenml.steps import step\n",
    "from zenml.environment import Environment\n",
    "\n",
    "# This is a private ZenML Discord channel. We will get notified if you use \n",
    "# this, but you won't be able to see it. Feel free to create a new Discord \n",
    "# [webhook](https://support.discord.com/hc/en-us/articles/228383668-Intro-to-Webhooks) \n",
    "# and replace this one!\n",
    "DISCORD_URL = (\n",
    "    \"https://discord.com/api/webhooks/935835443826659339/Q32jTwmqc\"\n",
    "    \"GJAUr-r_J3ouO-zkNQPchJHqTuwJ7dK4wiFzawT2Gu97f6ACt58UKFCxEO9\"\n",
    ")\n",
    "\n",
    "\n",
    "@step(enable_cache=False)\n",
    "def discord_alert(\n",
    "    drift_report: dict\n",
    ") -> None:\n",
    "    \"\"\"Send a message to the discord channel to report drift.\n",
    "    Args:\n",
    "        deployment_decision: True if drift detected; false otherwise.\n",
    "    \"\"\"\n",
    "    drift = drift_report[\"data_drift\"][\"data\"][\"metrics\"][\"dataset_drift\"]\n",
    "    url = DISCORD_URL\n",
    "    \n",
    "\n",
    "    env = Environment().step_environment\n",
    "    env.pipeline_name, env.pipeline_run_id, env.step_name\n",
    "    \n",
    "    content = f\"Message from pipeline: **{env.pipeline_name}**, run: **{env.pipeline_run_id}**, step: **{env.step_name}**\"\n",
    "    content += \"\\n\\n\"\n",
    "    content += \"Drift Detected!\" if drift else \"No Drift Detected!\"\n",
    "    \n",
    "    data = {\n",
    "        \"content\": content,\n",
    "        \"username\": \"Drift Bot\",\n",
    "    }\n",
    "    result = requests.post(url, json=data)\n",
    "\n",
    "    try:\n",
    "        result.raise_for_status()\n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        print(err)\n",
    "    else:\n",
    "        print(\n",
    "            \"Posted to discord successfully, code {}.\".format(\n",
    "                result.status_code\n",
    "            )\n",
    "        )\n",
    "    print(\"Drift detected\" if drift else \"No Drift detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evidently_profile_config = EvidentlyProfileConfig(\n",
    "    column_mapping=None,\n",
    "    profile_sections=[\"datadrift\"])\n",
    "\n",
    "third_pipeline = digits_pipeline_with_drift_alert(\n",
    "    importer=importer(),\n",
    "    trainer=svc_trainer(),\n",
    "    evaluator=evaluator(),\n",
    "    \n",
    "    # EvidentlyProfileStep takes reference_dataset and comparison dataset\n",
    "    get_reference_data=get_reference_data(),\n",
    "    drift_detector=EvidentlyProfileStep(config=evidently_profile_config),\n",
    "    \n",
    "    # Add discord\n",
    "    alerter=discord_alert()\n",
    ")\n",
    "third_pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track experiments and parameters with MLFlow\n",
    "\n",
    "For this pipeline we want to take you a step further by showing you some more integrations. We will be using MLFlow Tracking for visualizing and comparing multiple pipeline runs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MLflow](_assets/evidently+discord+mlflow.png \"MLflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a trainer with mlflow logging\n",
    "\n",
    "Now that we have mlflow enabled we need to choose what we want to log into mlflow. For now, we have chosen to use the [mlflow autolog](https://www.mlflow.org/docs/latest/tracking.html#scikit-learn) functionality to automatically log the model and training parameters within the training step.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note:</b> The @enable_mlflow decorator above the step is all we need to get started with mlflow. This decorator sets up an mlflow experiment and an mlflow backend for all runs within this pipeline. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Pipeline4](_assets/chapter_1/fourth_pipeline.png \"Pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.integrations.mlflow.mlflow_step_decorator import enable_mlflow\n",
    "import mlflow\n",
    "\n",
    "\n",
    "@enable_mlflow\n",
    "@step(enable_cache=False)\n",
    "def svc_trainer_mlflow(\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    ") -> ClassifierMixin:\n",
    "    \"\"\"Train another simple sklearn classifier for the digits dataset.\"\"\"\n",
    "    mlflow.sklearn.autolog()\n",
    "    model = SVC(gamma=0.001)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourth_pipeline = digits_pipeline_with_drift_alert(\n",
    "    importer=importer(),\n",
    "    trainer=svc_trainer_mlflow(),\n",
    "    evaluator=evaluator(),\n",
    "    \n",
    "    # EvidentlyProfileStep takes reference_dataset and comparison dataset\n",
    "    get_reference_data=get_reference_data(),\n",
    "    drift_detector=EvidentlyProfileStep(config=evidently_profile_config),\n",
    "    \n",
    "    # Add discord\n",
    "    alerter=discord_alert()\n",
    ")\n",
    "fourth_pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use native mlflow features\n",
    "\n",
    "Training is done, let's have a look at our mlflow ui and see if our training including the model have made it in there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will start a serving process for mlflow \n",
    "#  - if you want to continue in the notebook you need to manually\n",
    "#  interrupt the kernel \n",
    "from zenml.environment import Environment\n",
    "from zenml.integrations.mlflow.mlflow_environment import MLFLOW_ENVIRONMENT_NAME\n",
    "\n",
    "!mlflow ui --backend-store-uri {Environment()[MLFLOW_ENVIRONMENT_NAME].tracking_uri} --port 4998\n",
    "\n",
    "Environment()[MLFLOW_ENVIRONMENT_NAME].tracking_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create another trainer with a different model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Pipeline1](_assets/chapter_1/fixth_pipeline.png \"Pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@enable_mlflow\n",
    "@step(enable_cache=False)\n",
    "def tree_trainer_with_mlflow(\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    ") -> ClassifierMixin:\n",
    "    \"\"\"Train another simple sklearn classifier for the digits dataset.\"\"\"\n",
    "    mlflow.sklearn.autolog()\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifth_pipeline = digits_pipeline_with_drift_alert(\n",
    "    importer=importer(),\n",
    "    trainer=tree_trainer_with_mlflow(),\n",
    "    evaluator=evaluator(),\n",
    "    \n",
    "    # EvidentlyProfileStep takes reference_dataset and comparison dataset\n",
    "    get_reference_data=get_reference_data(),\n",
    "    drift_detector=EvidentlyProfileStep(config=evidently_profile_config),\n",
    "    \n",
    "    # Add discord\n",
    "    alerter=discord_alert()\n",
    ")\n",
    "fifth_pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will start a serving process for mlflow \n",
    "#  - if you want to continue in the notebook you need to manually\n",
    "#  interrupt the kernel \n",
    "from zenml.environment import Environment\n",
    "from zenml.integrations.mlflow.mlflow_environment import MLFLOW_ENVIRONMENT_NAME\n",
    "\n",
    "!mlflow ui --backend-store-uri {Environment()[MLFLOW_ENVIRONMENT_NAME].tracking_uri} --port 4998"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Continous Deployment to your ML pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Pipeline5](_assets/chapter_1/sixth_pipeline.png \"Pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline(enable_cache=False)\n",
    "def continuous_deployment_pipeline_notebook(\n",
    "    importer,\n",
    "    trainer,\n",
    "    evaluator,\n",
    "    get_reference_data,\n",
    "    drift_detector,\n",
    "    alerter,\n",
    "    \n",
    "    deployment_trigger,\n",
    "    model_deployer,\n",
    "):\n",
    "    \"\"\"Links all the steps together in a pipeline\"\"\"\n",
    "    X_train, X_test, y_train, y_test = importer()\n",
    "    model = trainer(X_train=X_train, y_train=y_train)\n",
    "    evaluator(X_test=X_test, y_test=y_test, model=model)\n",
    "    \n",
    "    reference, comparison = get_reference_data(X_train, X_test)\n",
    "    drift_report, _ = drift_detector(reference, comparison)\n",
    "    \n",
    "    alerter(drift_report)\n",
    "    \n",
    "    # new \n",
    "    deployment_decision = deployment_trigger(drift_report)\n",
    "    model_deployer(deployment_decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define deployment trigger and deployer step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def deployment_trigger(\n",
    "    drift_report: dict,\n",
    ") -> bool:\n",
    "    \"\"\"Implements a simple model deployment trigger that looks at the\n",
    "    drift report and deploys if there's none\"\"\"\n",
    "\n",
    "    drift = drift_report[\"data_drift\"][\"data\"][\"metrics\"][\"dataset_drift\"]\n",
    "\n",
    "    if drift:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.integrations.mlflow.steps import mlflow_deployer_step, MLFlowDeployerConfig\n",
    "from zenml.services import load_last_service_from_step\n",
    "\n",
    "model_deployer_ml = mlflow_deployer_step(name=\"model_deployer\")\n",
    "\n",
    "\n",
    "sixth_pipeline = continuous_deployment_pipeline_notebook(\n",
    "    importer=importer(),\n",
    "    trainer=tree_trainer_with_mlflow(),\n",
    "    evaluator=evaluator(),\n",
    "    \n",
    "    # EvidentlyProfileStep takes reference_dataset and comparison dataset\n",
    "    get_reference_data=get_reference_data(),\n",
    "    drift_detector=EvidentlyProfileStep(config=evidently_profile_config),\n",
    "    \n",
    "    # Add discord\n",
    "    alerter=discord_alert(),\n",
    "    \n",
    "    deployment_trigger=deployment_trigger(),\n",
    "    model_deployer=model_deployer_ml(config=MLFlowDeployerConfig(workers=1)),\n",
    ")\n",
    "sixth_pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interact with deployed model service directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = Repository()\n",
    "p = repo.get_pipeline('continuous_deployment_pipeline_notebook')\n",
    "last_run = p.runs[-1]\n",
    "X_test = last_run.steps[0].outputs['X_test'].read()\n",
    "y_test = last_run.steps[0].outputs['y_test'].read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = load_last_service_from_step(\n",
    "    pipeline_name=\"continuous_deployment_pipeline_notebook\",\n",
    "    step_name=\"model_deployer\",\n",
    "    running=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.check_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[0], y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "service.predict(X_test[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ax.set_axis_off()\n",
    "plt.imshow(X_test[0].reshape(8, 8), cmap=plt.cm.gray_r, interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Continous Inference pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch data in real time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MLflow](_assets/ZenML0-6-2.gif \"ZenML\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_api():\n",
    "    data = np.array([[ 0.,  0.,  1., 11., 14., 15.,  3.,  0.,  0.,  1., 13., 16., 12.,\n",
    "        16.,  8.,  0.,  0.,  8., 16.,  4.,  6., 16.,  5.,  0.,  0.,  5.,\n",
    "        15., 11., 13., 14.,  0.,  0.,  0.,  0.,  2., 12., 16., 13.,  0.,\n",
    "         0.,  0.,  0.,  0., 13., 16., 16.,  6.,  0.,  0.,  0.,  0., 16.,\n",
    "        16., 16.,  7.,  0.,  0.,  0.,  0., 11., 13., 12.,  1.,  0.]])\n",
    "    # data = np.array([x.reshape(1, 8, 8) for x in data])\n",
    "    return data\n",
    "\n",
    "\n",
    "@step(enable_cache=False)\n",
    "def dynamic_importer() -> Output(data=np.ndarray):\n",
    "    \"\"\"Downloads the latest data from a mock API.\"\"\"\n",
    "    data = get_data_from_api()\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the latest deployed model and run inference on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.steps import BaseStepConfig, StepContext\n",
    "from zenml.integrations.mlflow.services import MLFlowDeploymentService\n",
    "\n",
    "class MLFlowDeploymentLoaderStepConfig(BaseStepConfig):\n",
    "    \"\"\"MLflow deployment getter configuration\n",
    "    Attributes:\n",
    "        pipeline_name: name of the pipeline that deployed the MLflow prediction\n",
    "            server\n",
    "        step_name: the name of the step that deployed the MLflow prediction\n",
    "            server\n",
    "        running: when this flag is set, the step only returns a running service\n",
    "    \"\"\"\n",
    "\n",
    "    pipeline_name: str\n",
    "    step_name: str\n",
    "    running: bool = True\n",
    "\n",
    "\n",
    "@step(enable_cache=False)\n",
    "def prediction_service_loader(\n",
    "    config: MLFlowDeploymentLoaderStepConfig, context: StepContext\n",
    ") -> MLFlowDeploymentService:\n",
    "    \"\"\"Get the prediction service started by the deployment pipeline\"\"\"\n",
    "\n",
    "    service = load_last_service_from_step(\n",
    "        pipeline_name=config.pipeline_name,\n",
    "        step_name=config.step_name,\n",
    "        step_context=context,\n",
    "        running=config.running,\n",
    "    )\n",
    "    if not service:\n",
    "        raise RuntimeError(\n",
    "            f\"No MLflow prediction service deployed by the \"\n",
    "            f\"{config.step_name} step in the {config.pipeline_name} pipeline \"\n",
    "            f\"is currently running.\"\n",
    "        )\n",
    "\n",
    "    return service\n",
    "\n",
    "\n",
    "\n",
    "@step\n",
    "def predictor(\n",
    "    service: MLFlowDeploymentService,\n",
    "    data: np.ndarray,\n",
    ") -> Output(predictions=list):\n",
    "    \"\"\"Run a inference request against a prediction service\"\"\"\n",
    "    service.start(timeout=10)  # should be a NOP if already started\n",
    "    prediction = service.predict(data)\n",
    "    prediction = prediction.argmax(axis=-1)\n",
    "    print(f\"Prediction is: {[prediction.tolist()]}\")\n",
    "    return [prediction.tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the CI pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline\n",
    "def inference_pipeline(\n",
    "    dynamic_importer,\n",
    "    prediction_service_loader,\n",
    "    predictor,\n",
    "):\n",
    "    # Link all the steps artifacts together\n",
    "    batch_data = dynamic_importer()\n",
    "    model_deployment_service = prediction_service_loader()\n",
    "    predictor(model_deployment_service, batch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an inference pipeline run\n",
    "inference = inference_pipeline(\n",
    "    dynamic_importer=dynamic_importer(),\n",
    "    prediction_service_loader=prediction_service_loader(\n",
    "        MLFlowDeploymentLoaderStepConfig(\n",
    "            pipeline_name=\"continuous_deployment_pipeline_notebook\",\n",
    "            step_name=\"model_deployer\",\n",
    "        )\n",
    "    ),\n",
    "    predictor=predictor(),\n",
    ")\n",
    "\n",
    "inference.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
