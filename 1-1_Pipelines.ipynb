{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 1.1: ML Pipelines with ZenML\n",
    "\n",
    "***Key Concepts:*** *ML Pipelines, Steps*\n",
    "\n",
    "In this notebook we will learn how to easily convert existing ML code into ML pipelines using ZenML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will build models with [sklearn](https://scikit-learn.org/stable/), you will need to have the ZenML sklearn integration installed. If you have not done so before, install it with the following command, then restart the kernel of your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml integration install sklearn -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an ML practitioner, you are probably familiar with how to build ML models with Scikit-learn, PyTorch, TensorFlow, or similar.\n",
    "An **[ML Pipeline](https://docs.zenml.io/core-concepts#pipeline)** is simply an extension of that, which also includes other steps you would typically do before or after building a model, like data acquisition, preprocessing, model deployment, or monitoring. In essence, the ML pipeline defines a step-by-step procedure of your work as ML practitioner.\n",
    "Defining ML pipelines explicitly in code is great because:\n",
    "- We can easily rerun *all* of our work, not just the model. This eliminates bugs and makes our models easier to reproduce.\n",
    "- Data and models can be versioned and tracked, so we can see at a glance which dataset a model was trained on and how it compares to other models.\n",
    "- If the entire pipeline is coded up, we can automate many operational tasks, like retraining and redeploying models when the underlying problem or data changes, or rolling out new and improved models with CI/CD workflows.\n",
    "\n",
    "For ML teams that aim to serve models at large scale, having a clearly defined ML pipeline is a must."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZenML Setup\n",
    "Throughout this series, we will define our ML pipelines using [ZenML](https://github.com/zenml-io/zenml/). ZenML is an excellent tool for this task, as it is very easy and intuitive to use and has [integrations](https://docs.zenml.io/features/integrations) with most of the advanced MLOps tools we will want to use later. Make sure you have ZenML installed (via `pip install zenml`). In the following, we run some commands to make sure you start out with a fresh ML stack. You can ignore this for now as it will be explained in more detail in a later chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf .zen\n",
    "!zenml init\n",
    "!zenml stack set default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Experimentation ML Code\n",
    "Let us get started with some simple examplary ML code. In the following, we train a Scikit-learn SVC classifier to classify images of handwritten digits. We load the data, train a model on the training set, then test it on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.svm import SVC\n",
    "from zenml.integrations.sklearn.helpers.digits import get_digits\n",
    "\n",
    "\n",
    "def train_test() -> None:\n",
    "    \"\"\"Train and test a Scikit-learn SVC classifier on digits\"\"\"\n",
    "    X_train, X_test, y_train, y_test = get_digits()\n",
    "    model = SVC(gamma=0.001)\n",
    "    model.fit(X_train, y_train)\n",
    "    test_acc = model.score(X_test, y_test)\n",
    "    print(f\"Test accuracy: {test_acc}\")\n",
    "\n",
    "\n",
    "train_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning experiments into ML pipelines with ZenML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, your ML workflows will of course be much more complicated than that. You might have complex preprocessing that you do not want to redo every time you train a model, you will need to compare the performance of different models, deploy them in a production setting, and much more. This is where ML pipelines come into play, which allow us to define our workflows in distinct modular steps that we can then mix and match.\n",
    "\n",
    "![Digits Pipeline](_assets/1-1/digits_pipeline.png)\n",
    "\n",
    "In our example, we can identify three distinct steps: data loading, model training, and model evaluation. Let us now define each of them as a ZenML **[Pipeline Step](https://docs.zenml.io/core-concepts#step)**, simply by moving each step to it's own function and decorating them with ZenML's `@step` [Python decorator](https://realpython.com/primer-on-python-decorators/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.steps import step, Output\n",
    "\n",
    "\n",
    "@step\n",
    "def importer() -> Output(\n",
    "    X_train=np.ndarray,\n",
    "    X_test=np.ndarray,\n",
    "    y_train=np.ndarray,\n",
    "    y_test=np.ndarray,\n",
    "):\n",
    "    \"\"\"Load the digits dataset as numpy arrays.\"\"\"\n",
    "    X_train, X_test, y_train, y_test = get_digits()\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "@step\n",
    "def svc_trainer(\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    ") -> ClassifierMixin:\n",
    "    \"\"\"Train a sklearn SVC classifier.\"\"\"\n",
    "    model = SVC(gamma=0.001)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "\n",
    "@step\n",
    "def evaluator(\n",
    "    X_test: np.ndarray,\n",
    "    y_test: np.ndarray,\n",
    "    model: ClassifierMixin,\n",
    ") -> float:\n",
    "    \"\"\"Calculate the test set accuracy of an sklearn model.\"\"\"\n",
    "    test_acc = model.score(X_test, y_test)\n",
    "    print(f\"Test accuracy: {test_acc}\")\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can use ZenML's `@pipeline` decorator to connect all of our steps into a ML pipeline.\n",
    "\n",
    "Note that the pipeline definition does not depend on the concrete step functions we defined above, it merely defines a recipe for how data moves through the steps. This means we can replace steps as we wish, e.g., to run the same pipeline with different models to compare their performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.pipelines import pipeline\n",
    "\n",
    "\n",
    "@pipeline\n",
    "def digits_pipeline(importer, trainer, evaluator):\n",
    "    \"\"\"Links all the steps together in a pipeline\"\"\"\n",
    "    X_train, X_test, y_train, y_test = importer()\n",
    "    model = trainer(X_train=X_train, y_train=y_train)\n",
    "    evaluator(X_test=X_test, y_test=y_test, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running ZenML Pipelines\n",
    "Finally, to run our pipeline, we simply initialize it with concrete step functions and call the `run()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_svc_pipeline = digits_pipeline(\n",
    "    importer=importer(), trainer=svc_trainer(), evaluator=evaluator()\n",
    ")\n",
    "digits_svc_pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it, we just built our first ML pipeline! Great job!\n",
    "\n",
    "In the [next lesson](1-2_Artifact_Lineage.ipynb), you will see one of the coolest features of ML pipelines in action: automated artifact versioning and caching. See you there!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9f70ec6e6bd16014ded89c8222361cbe53cd9507d51ebdcdf3ab6e494d45cf74"
  },
  "kernelspec": {
   "display_name": "zenbytes",
   "language": "python",
   "name": "zenbytes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
