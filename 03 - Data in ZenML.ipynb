{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How Data Flows In ZenML\n",
    "\n",
    "Pipelines in ZenML are data-centric. This means that data forms the link between different steps in a pipeline. In other words, the flow of the pipeline execution is data based and not task or function based. \n",
    "\n",
    "Since data holds such an integral position in the workflow, it is important to be able to track and maintain it seamlessly across all steps. In this chapter we will see how ZenML takes care of tracking your artifacts and all relevant metadata automatically and makes it available to be used and analyzed using a host of first class integration with tools like Evidently, MLflow and Wandb among others!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZenML behind the scenes\n",
    "\n",
    "Let's look at a simple pipeline from before. ZenML works behind the scenes to store the outputs of each step and make them accessible to all other steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from steps import importer, trainer, evaluator\n",
    "from zenml.pipelines import pipeline\n",
    "from zenml.steps import Output, step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition of our pipeline\n",
    "@pipeline\n",
    "def digits_pipeline(\n",
    "    importer,\n",
    "    trainer,\n",
    "    evaluator,\n",
    "):\n",
    "    \"\"\"Links all the steps together in a pipeline\"\"\"\n",
    "    X_train, X_test, y_train, y_test = importer()\n",
    "    model = trainer(X_train=X_train, y_train=y_train)\n",
    "    evaluator(X_test=X_test, y_test=y_test, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diving deeper\n",
    "We can see that these steps are linked together with their inputs and outputs. If we dive into the code of one of the steps, we can notice that the artifacts for this step are strongly typed. In the example below, the output is clearly specified as an object of type `ClassifierMixin`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "@step\n",
    "def svc_trainer(\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    ") -> ClassifierMixin:\n",
    "    \"\"\"Train another simple sklearn classifier for the digits dataset.\"\"\"\n",
    "    print(\"test\")\n",
    "    model = SVC(gamma=0.001)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Materializers\n",
    "\n",
    "Having the knowledge of the type of artifacts produced by a step allows ZenML to pair the type with its corresponding \"materializer\". Materializers in ZenML are responsible for defining the logic for storing an artifact as a specific file type. Some types are supported by built-in materializers right out of the box, such as for libraries like numpy, pandas, pytorch, sklearn and more. In the case where you have a type of output which is not yet supported by ZenML, you can very easily implement one on your own!\n",
    "\n",
    "Let's build a custom materializer for the `ClassifierMixin` type for our trainer step. A ZenML implementation already exists and so this would be redundant but it serves as a good exercise on just how easy it is to replace a few values and have your own materializer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from typing import Any, Type\n",
    "import pickle\n",
    "\n",
    "from zenml.materializers.base_materializer import BaseMaterializer\n",
    "from zenml.io import fileio\n",
    "from zenml.steps import step\n",
    "\n",
    "DEFAULT_FILENAME = 'model'\n",
    "\n",
    "class SklearnMaterializer(BaseMaterializer):\n",
    "    \"\"\"Materializer to read data to and from sklearn.\"\"\"\n",
    "\n",
    "    ASSOCIATED_TYPES = (\n",
    "        ClassifierMixin,\n",
    "    )\n",
    "\n",
    "    def handle_input(\n",
    "        self, data_type: Type[Any]\n",
    "    ) -> ClassifierMixin:\n",
    "        \"\"\"Reads a ClassifierMixin model from a pickle file.\"\"\"\n",
    "        super().handle_input(data_type)\n",
    "        filepath = os.path.join(self.artifact.uri, DEFAULT_FILENAME)\n",
    "        with fileio.open(filepath, \"rb\") as fid:\n",
    "            clf = pickle.load(fid)\n",
    "        return clf\n",
    "\n",
    "    def handle_return(\n",
    "        self,\n",
    "        clf: ClassifierMixin\n",
    "    ) -> None:\n",
    "        \"\"\"Creates a pickle for a ClassifierMixin model\n",
    "\n",
    "        Args:\n",
    "            clf: A ClassifierMixin model.\n",
    "        \"\"\"\n",
    "        super().handle_return(clf)\n",
    "        filepath = os.path.join(self.artifact.uri, DEFAULT_FILENAME)\n",
    "        with fileio.open(filepath, \"wb\") as fid:\n",
    "            pickle.dump(clf, fid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Few important points to notice\n",
    "- The `ASSOCIATED_TYPES` field contains the types which you want this materializer to be used for. \n",
    "- The `handle_input` function holds the logic for reading the specific type.\n",
    "- The `handle_return` function holds the logic for storing the type to a file format of your choice.\n",
    "\n",
    "In this example, we have used `pickle` to save and load our `ClassifierMixin` python object for simplicity. You can choose to have other specialised implementations depending on the type used and its corresponding best practices. \n",
    "\n",
    "You can resuse this code and replace the values in the associated types to quickly build a materializer for your custom needs. For more examples and different implementations, check out our docs on [custom materializers](https://docs.zenml.io/guides/functional-api/materialize-artifacts#create-custom-materializer) and the code for built-in materializers on our GitHub!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While running the pipeline, you specify your custom materializer for your step by using the function `with_return_materializer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and run the pipeline\n",
    "first_pipeline = digits_pipeline(\n",
    "    importer=importer.importer(),\n",
    "    trainer=trainer.svc_trainer_mlflow().with_return_materializers(SklearnMaterializer),\n",
    "    evaluator=evaluator.evaluator(),\n",
    ")\n",
    "first_pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where do the artifacts go?\n",
    "The artifacts are stored in an artifact store which you can configure as a part of your stack. Chapter 2 deals with switching between stacks and shows how easy the process is. \n",
    "The artifacts are referenced through a metadata store, also configurable through the stack. It holds the artifacts URIs for all steps across all pipeline runs! Head over to our [concepts page](https://docs.zenml.io/core-concepts) to learn more.\n",
    "\n",
    "IMAGE of stack maybe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing artifacts from within a step\n",
    "The metadata store can be accessed from inside a step and this adds a lot of possibilities when it commes to interacting with your data and making smart decisions from them.\n",
    "Let's modify one of our steps to include a `StepContext` object as a parameter to it. `StepContext` provides additional and is used to access materializers and artifact URIs inside a step function.\n",
    "\n",
    "We will use the metadata store to fetch the trained models from all past runs of our pipeline and then select the best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.steps import StepContext\n",
    "\n",
    "@step\n",
    "def evaluate_best_model(\n",
    "    X_test: np.ndarray,\n",
    "    Y_test: np.ndarray,\n",
    "    model: ClassifierMixin,\n",
    "    context: StepContext\n",
    ") -> Output(current_acc=float, best_acc=float, model=ClassifierMixin):\n",
    "    \"\"\"Calculate the accuracy on the test set\"\"\"\n",
    "    best_acc = model.score(X_test, Y_test)\n",
    "    current_acc = best_acc\n",
    "    best_model = model\n",
    "    print(f\"Current test accuracy: {best_acc}\")\n",
    "    \n",
    "    metadata_store = context.metadata_store  # can access all of metadata store's functions here\n",
    "    \n",
    "    pipeline_runs = metadata_store.get_pipeline(\"digits_pipeline\").runs\n",
    "    for run in pipeline_runs:\n",
    "        # get the trained model of all pipeline runs\n",
    "        model = run.get_step(\"trainer\").output.read()\n",
    "        accuracy = model.score(X_test, Y_test)\n",
    "        if accuracy > best_acc:\n",
    "            # if the model accuracy is better than our currently-best model,\n",
    "            # store it\n",
    "            best_acc = accuracy\n",
    "            best_model = model\n",
    "    \n",
    "    return current_acc, best_acc, best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this was the last step in our pipeline and we are not using the outputs from this step in any other steps, we won't need to redefine our pipeline for it to work. The only difference between the newer runs and the older runs would be that, after execution, we will now be able to get the best model stored as an output artifact for the last step (along with the accuracies). We will see more of how to access those artifacts in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and run the pipeline\n",
    "second_pipeline = digits_pipeline(\n",
    "    importer=importer.importer(),\n",
    "    trainer=trainer.svc_trainer_mlflow().with_return_materializers(SklearnMaterializer),\n",
    "    evaluator=evaluate_best_model(),\n",
    ")\n",
    "second_pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing data from a pipeline run\n",
    "Now that you understand the logic that goes behind making your artifacts accessible between steps, let's move forward with our data journey. Your data is available to you not only between and within steps but even after a pipeline has finished executing. Data from historical pipeline runs is saved and versioned by ZenML and can be accessed in the post execution workflow. \n",
    "We will now use this feature to investigate the previous two pipeline runs and check if the second pipeline returned the best accuracy value as we had designed it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.repository import Repository\n",
    "\n",
    "repo = Repository()\n",
    "# get our pipeline\n",
    "pipeline = repo.get_pipeline(pipeline_name='digits_pipeline')\n",
    "# this is the first_pipeline run\n",
    "second_latest_run = pipeline.runs[-2]\n",
    "# in this run, the third step (evaluator) has only one output.\n",
    "# so we use steps.output function\n",
    "accuracy_from_first_run = second_latest_run.steps[2].output\n",
    "accuracy_from_first_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the second_pipeline run\n",
    "latest_run = pipeline.runs[-1]\n",
    "# here, there are multiple outputs. we choose the cuurent accuracy output\n",
    "accuracy_from_second_run = latest_run.steps[2].outputs[\"current_acc\"]\n",
    "accuracy_from_second_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's check what the best accuracy value is, from the latest pipeline run and check if it is the higher of the two accuracies that we have obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the best accuracy output\n",
    "best_accuracy = latest_run.steps[2].outputs[\"best_acc\"]\n",
    "best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The code above is logical and valid on the assumption that the order of execution is first the `first_pipeline`, then the `second_pipeline` and then this code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing data through integrations\n",
    "\n",
    "ZenML offers integrations with tools like Evidently, MLflow, Tensorboard and Wandb among others to help you better track, visualize and learn from your data. [Chapter 1](./01%20-%20Training%20Pipeline.ipynb) shows how you can leverage the MLflow integration to track your artifacts and then visualize them through the MLflow UI."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1d7600ed8f066347ae17884337d26dc6ef48c8183b35a1fb8cb1506c8d80f63d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('zenenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
