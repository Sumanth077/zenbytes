{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How Data Flows In ZenML\n",
    "\n",
    "Pipelines in ZenML are data-centric. This means that data forms the link between different steps in a pipeline. In other words, the flow of the pipeline execution is data based and not task or function based. \n",
    "\n",
    "Since data holds such an integral position in the workflow, it is important to be able to track and maintain it seamlessly across all steps. In this chapter we will see how ZenML takes care of tracking your artifacts and all relevant metadata automatically and makes it available to be used and analyzed using a host of first class integration with tools like Evidently, MLflow and Wandb among others!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZenML behind the scenes\n",
    "\n",
    "Let's look at a simple pipeline from before. ZenML works behind the scenes to store the outputs of each step and make them accessible to all other steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from steps import importer, trainer, evaluator\n",
    "from zenml.pipelines import pipeline\n",
    "from zenml.steps import Output, step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition of our pipeline\n",
    "@pipeline\n",
    "def digits_pipeline(\n",
    "    importer,\n",
    "    trainer,\n",
    "    evaluator,\n",
    "):\n",
    "    \"\"\"Links all the steps together in a pipeline\"\"\"\n",
    "    X_train, X_test, y_train, y_test = importer()\n",
    "    model = trainer(X_train=X_train, y_train=y_train)\n",
    "    evaluator(X_test=X_test, y_test=y_test, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diving deeper\n",
    "We can see that these steps are linked together with their inputs and outputs. If we dive into the code of one of the steps, we can notice that the artifacts for this step are strongly typed. In the example below, the output is clearly specified as an object of type `ClassifierMixin`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "@step\n",
    "def svc_trainer(\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    ") -> ClassifierMixin:\n",
    "    \"\"\"Train another simple sklearn classifier for the digits dataset.\"\"\"\n",
    "    print(\"test\")\n",
    "    model = SVC(gamma=0.001)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Materializers\n",
    "\n",
    "Having the knowledge of the type of artifacts produced by a step allows ZenML to pair the type with its corresponding \"materializer\". Materializers in ZenML are responsible for defining the logic for storing an artifact as a specific file type. Some types are supported by built-in materializers right out of the box, such as for libraries like numpy, pandas, pytorch, sklearn and more. In the case where you have a type of output which is not yet supported by ZenML, you can very easily implement one on your own!\n",
    "\n",
    "Let's build a custom materializer for the `ClassifierMixin` type for our trainer step. A ZenML implementation already exists and so this would be redundant but it serves as a good exercise on just how easy it is to replace a few values and have your own materializer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from typing import Any, Type\n",
    "import pickle\n",
    "\n",
    "from zenml.materializers.base_materializer import BaseMaterializer\n",
    "from zenml.io import fileio\n",
    "from zenml.steps import step\n",
    "\n",
    "DEFAULT_FILENAME = 'model'\n",
    "\n",
    "class SklearnMaterializer(BaseMaterializer):\n",
    "    \"\"\"Materializer to read data to and from sklearn.\"\"\"\n",
    "\n",
    "    ASSOCIATED_TYPES = (\n",
    "        ClassifierMixin,\n",
    "    )\n",
    "\n",
    "    def handle_input(\n",
    "        self, data_type: Type[Any]\n",
    "    ) -> ClassifierMixin:\n",
    "        \"\"\"Reads a ClassifierMixin model from a pickle file.\"\"\"\n",
    "        super().handle_input(data_type)\n",
    "        filepath = os.path.join(self.artifact.uri, DEFAULT_FILENAME)\n",
    "        with fileio.open(filepath, \"rb\") as fid:\n",
    "            clf = pickle.load(fid)\n",
    "        return clf\n",
    "\n",
    "    def handle_return(\n",
    "        self,\n",
    "        clf: ClassifierMixin\n",
    "    ) -> None:\n",
    "        \"\"\"Creates a pickle for a ClassifierMixin model\n",
    "\n",
    "        Args:\n",
    "            clf: A ClassifierMixin model.\n",
    "        \"\"\"\n",
    "        super().handle_return(clf)\n",
    "        filepath = os.path.join(self.artifact.uri, DEFAULT_FILENAME)\n",
    "        with fileio.open(filepath, \"wb\") as fid:\n",
    "            pickle.dump(clf, fid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Few important points to notice\n",
    "- The `ASSOCIATED_TYPES` field contains the types which you want this materializer to be used for. \n",
    "- The `handle_input` function holds the logic for reading the specific type.\n",
    "- The `handle_return` function holds the logic for storing the type to a file format of your choice.\n",
    "\n",
    "In this example, we have used `pickle` to save and load our `ClassifierMixin` python object for simplicity. You can choose to have other specialised implementations depending on the type used and its corresponding best practices. \n",
    "\n",
    "You can resuse this code and replace the values in the associated types to quickly build a materializer for your custom needs. For more examples and different implementations, check out our docs on [custom materializers](https://docs.zenml.io/guides/functional-api/materialize-artifacts#create-custom-materializer) and the code for built-in materializers on our GitHub!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the pipeline\n",
    "first_pipeline = digits_pipeline(\n",
    "    importer=importer(),\n",
    "    trainer=trainer.svc_trainer_mlflow(),\n",
    "    evaluator=evaluator(),\n",
    ")\n",
    "first_pipeline.run()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1d7600ed8f066347ae17884337d26dc6ef48c8183b35a1fb8cb1506c8d80f63d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('zenenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
