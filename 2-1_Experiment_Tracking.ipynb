{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 2.1 - Experiment Tracking with MLflow / W&B\n",
    "\n",
    "***Key Concepts:*** *Experiment Trackers, MLflow, Weights & Biases*\n",
    "\n",
    "When training your own models, you can easily get overwhelmed by the large number of different experiments you conduct and you might find yourself losing track of how different hyperparameters affected your model performance, or what exact configuration produced the best model you had trained. That is why experiment tracking tools like Tensorboard, Weights & Biases, or MLflow are often one of the first touchpoints you will have with MLOps as you progress through your ML journey.\n",
    "\n",
    "In this lesson, we will learn how to effectively track experiments with MLflow, which is the most popular open-source experiment tracking tool.\n",
    "For those of you already familiar with experiment tracking tools, we also have a short bonus section at the end on how to use Weights & Biases instead of MLflow in your ZenML pipelines.\n",
    "\n",
    "To get started, run the following commands to install both tools with their respective dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml integration install mlflow -f\n",
    "!zenml integration install wandb -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's import our pipeline definition and some of the pipeline steps that we built in the previous lessons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.steps.evaluator import evaluator\n",
    "from src.steps.importer import importer\n",
    "from src.pipelines.digits_pipeline import digits_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow Experiment Tracking\n",
    "\n",
    "[MLflow](https://mlflow.org/) is an amazing open-source MLOps platform that provides powerful tools to handle various ML lifecycle steps, such as experiment tracking, code packaging, model deployment, and more. In this lesson, we will focus on the [MLflow Tracking component](https://mlflow.org/docs/latest/tracking.html), but we will learn about other MLflow components in later lessons.\n",
    "\n",
    "To integrate the MLFlow experiment tracker into our previously defined ZenML pipeline, all we need to adjust is the `svc_trainer` step. To do so, we define a new step `svc_trainer_mlflow` in which we use MLflow's `mlflow.sklearn.autolog()` feature to automatically log all relevant attributes of our model to MLflow. By adding an `@enable_mlflow` decorator on top of the function, ZenML then automatically initializes MLflow and takes care of the rest for us.\n",
    "\n",
    "The following function creates such a step, parametrized by the SVC hyperparameter `gamma`, then returns a corresponding ML pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.svm import SVC\n",
    "import mlflow\n",
    "from zenml.integrations.mlflow.mlflow_step_decorator import enable_mlflow\n",
    "from zenml.steps import step, BaseStepConfig\n",
    "\n",
    "\n",
    "def build_svc_mlflow_pipeline(gamma=1e-3):\n",
    "    @enable_mlflow  # setup MLflow\n",
    "    @step(\n",
    "        enable_cache=False\n",
    "    )  # disable caching so we log **every** run to MLflow\n",
    "    def svc_trainer_mlflow(\n",
    "        X_train: np.ndarray,\n",
    "        y_train: np.ndarray,\n",
    "    ) -> ClassifierMixin:\n",
    "        \"\"\"Train a sklearn SVC classifier and log to MLflow.\"\"\"\n",
    "        mlflow.sklearn.autolog()  # log all model hparams and metrics to MLflow\n",
    "        model = SVC(gamma=gamma)\n",
    "        model.fit(X_train, y_train)\n",
    "        return model\n",
    "\n",
    "    return digits_pipeline(\n",
    "        importer=importer(),\n",
    "        trainer=svc_trainer_mlflow(),\n",
    "        evaluator=evaluator(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do the same for our decision tree trainer step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "def build_tree_mlflow_pipeline():\n",
    "    @enable_mlflow  # setup MLflow\n",
    "    @step(\n",
    "        enable_cache=False\n",
    "    )  # disable caching so we log **every** run to MLflow\n",
    "    def tree_trainer_with_mlflow(\n",
    "        X_train: np.ndarray,\n",
    "        y_train: np.ndarray,\n",
    "    ) -> ClassifierMixin:\n",
    "        \"\"\"Train a sklearn decision tree classifier and log to MLflow.\"\"\"\n",
    "        mlflow.sklearn.autolog()  # log all model hparams and metrics to MLflow\n",
    "        model = DecisionTreeClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "        return model\n",
    "\n",
    "    return digits_pipeline(\n",
    "        importer=importer(),\n",
    "        trainer=tree_trainer_with_mlflow(),\n",
    "        evaluator=evaluator(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to run our MLflow pipelines with ZenML, we first need to add MLflow into our ZenML MLOps stack.\n",
    "To do so, we first register a new experiment tracker with ZenML and then add it into our current stack.\n",
    "We can then use `zenml stack describe` to show an overview of our currently active MLOps stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the MLflow experiment tracker\n",
    "!zenml experiment-tracker register mlflow_tracker --type=mlflow\n",
    "\n",
    "# Add the MLflow experiment tracker into our default stack\n",
    "!zenml stack update default -e mlflow_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See an overview of your current MLOps stack\n",
    "!zenml stack describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it, we're all setup! Now we can simply call `pipeline.run()` for all of our pipelines to run them and automatically log all of our pipeline runs to MLflow. Let's try it out and do a few pipeline runs with different hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gamma in (1e-4, 1e-3, 1e-2, 1e-1):\n",
    "    build_svc_mlflow_pipeline(gamma=gamma).run()\n",
    "build_tree_mlflow_pipeline().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare all of our runs within the MLflow UI, run the following cell, then open http://127.0.0.1:4997/ in your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will start a serving process for mlflow\n",
    "#  - if you want to continue in the notebook you need to manually\n",
    "#  interrupt the kernel\n",
    "from zenml.integrations.mlflow.mlflow_utils import get_tracking_uri\n",
    "\n",
    "!mlflow ui --backend-store-uri=\"{get_tracking_uri()}\" --port=4997"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing you will see is an overview of all your runs as shown below:\n",
    "\n",
    "![MLflow UI](_assets/2-1/mlflow_ui.png)\n",
    "\n",
    "Click on the `Parameters >` tab on top of the table to see *all* hyperparameters of your model. Now you can see at a glance which model performed best and which hyperparameters changed between different runs. In our case, we can see that the SVC model with `gamma=0.001` achieved the best validation accuracy of `0.969`.\n",
    "\n",
    "If we click on one of the links in the `Start Time` column, we can see additional details of the respective run. In particular, under the `Artifacts` tab, we can find a `model.pkl` file, which we could now use to load our model in an inference/production environment to deploy it. In the next lesson, `2-2_Local_Deployment.ipynb`, we will learn how to do this automatically as part of our pipelines with the [MLflow Models component](https://mlflow.org/docs/latest/models.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative Tool: Weights & Biases\n",
    "\n",
    "Of course, MLflow is not the only tool you can use for experiment tracking. In the following example, we will show how we could achieve the same with another experiment tracking tool: Weights & Biases.\n",
    "This example assumes you already have some familiarity with W&B. In particular, you a need a Weights & Biases account, which you can set up for free [here](https://wandb.ai/login?signup=true).\n",
    "\n",
    "You then need to define the three variables below to authorize yourself in W&B and to tell ZenML which entity/project you want to log to:\n",
    "- `WANDB_API_KEY`: your API key, which you can retrieve at [https://wandb.ai/authorize](https://wandb.ai/authorize). Make sure to never share this key (in particular, make sure to remove the key before pushing this notebook to any public Git repositories!).\n",
    "- `WANDB_ENTITY`: the entity (team or user) that owns the project you want to log to. If you are using W&B alone, just use your username here.\n",
    "- `WANDB_PROJECT`: the name of the W&B project you want to log to. If you have never used W&B before or want to start a new project, simply type the new project name here, e.g., \"zenbytes\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WANDB_API_KEY = None  # TODO: replace this with your W&B API key\n",
    "WANDB_ENTITY = None  # TODO: replace this with your W&B entity name\n",
    "WANDB_PROJECT = \"zenbytes\"  # TODO: replace this with your W&B project name (if you want to log to a specific project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the W&B experiment tracker\n",
    "!zenml experiment-tracker register wandb_tracker --type=wandb --api_key={WANDB_API_KEY} --entity={WANDB_ENTITY} --project_name={WANDB_PROJECT}\n",
    "\n",
    "# Create a new stack with W&B experiment tracker in it\n",
    "!zenml stack register wandb_stack -m default -a default -o default -e wandb_tracker\n",
    "\n",
    "# Set it as the active stack\n",
    "!zenml stack set wandb_stack\n",
    "\n",
    "# See an overview of your current MLOps stack\n",
    "!zenml stack describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to add wandb to our `svc_trainer` step and use that to initialize our ZenML pipeline. The overall setup is the exact same as for the MLflow example above: we simply add an `@enable_wandb` decorator to our step and then we can use `wandb` functionality within the step as we wish.\n",
    "\n",
    "The main difference to the MLflow example before is that W&B has no sklearn autolog functionality. Instead, we need to call `wandb.log(...)` for each value we want to log to Weights & Biases.\n",
    "\n",
    "Since we also want to log our validation score, we need to adjust our `evaluator` step accordingly as well.\n",
    "\n",
    "Note that, despite wandb being used in different steps within a pipeline, ZenML handles initializing wandb and ensures that the experiment name is the same as the pipeline name and that the experiment run name is the same as the pipeline run name. This establishes a lineage between pipelines in ZenML and experiments in wandb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.svm import SVC\n",
    "import wandb\n",
    "from zenml.integrations.wandb.wandb_step_decorator import enable_wandb\n",
    "from zenml.steps import step, BaseStepConfig\n",
    "\n",
    "\n",
    "def build_svc_wandb_pipeline(gamma=1e-3):\n",
    "    @enable_wandb  # setup wandb\n",
    "    @step(enable_cache=False)\n",
    "    def svc_trainer_wandb(\n",
    "        X_train: np.ndarray,\n",
    "        y_train: np.ndarray,\n",
    "    ) -> ClassifierMixin:\n",
    "        \"\"\"Train a sklearn SVC classifier and log to W&B.\"\"\"\n",
    "        wandb.log({\"gamma\": gamma})  # log gamma hparam to wandb\n",
    "        model = SVC(gamma=gamma)\n",
    "        model.fit(X_train, y_train)\n",
    "        return model\n",
    "\n",
    "    @enable_wandb  # setup wandb\n",
    "    @step\n",
    "    def evaluator_wandb(\n",
    "        X_test: np.ndarray,\n",
    "        y_test: np.ndarray,\n",
    "        model: ClassifierMixin,\n",
    "    ) -> float:\n",
    "        \"\"\"Calculate the accuracy on the test set and log to W&B.\"\"\"\n",
    "        test_acc = evaluator(X_test, y_test, model)\n",
    "        wandb.log({\"test acc\": test_acc})  # log test_acc to wandb\n",
    "        return test_acc\n",
    "\n",
    "    return digits_pipeline(\n",
    "        importer=importer(),\n",
    "        trainer=svc_trainer_wandb(),\n",
    "        evaluator=evaluator_wandb(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, execute the cell below to run your pipeline with different gamma values. You should then see your runs recorded in your Weights & Biases project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gamma in (1e-4, 1e-3, 1e-2, 1e-1):\n",
    "    build_svc_wandb_pipeline(gamma=gamma).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will learn how to deploy models locally with MLflow in `2-2_Local_Deployment.ipynb`."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9f70ec6e6bd16014ded89c8222361cbe53cd9507d51ebdcdf3ab6e494d45cf74"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('zenbytes')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
