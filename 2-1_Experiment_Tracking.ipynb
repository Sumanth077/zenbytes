{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 2.1 - Experiment Tracking with W&B / MLflow\n",
    "\n",
    "***Key Concepts:*** *Experiment Trackers, Weights & Biases, MLflow*\n",
    "\n",
    "When training your own models, you can easily get overwhelmed by the large number of different experiments you conduct and you might find yourself losing track of how different hyperparameters affected your model performance, or what exact configuration produced the best model you had trained. That is why experiment tracking tools like Tensorboard, Weights & Biases, or MLflow are often one of the first touchpoints you will have with MLOps as you progress through your ML journey.\n",
    "\n",
    "In this lesson, we will learn about two of the most popular tools in this space: Weights & Biases and MLflow. Let's integrate them into our pipelines and see them in action!\n",
    "\n",
    "To get started, run the following commands to install both tools with their respective dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml integration install mlflow -f\n",
    "!zenml integration install wandb -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's import our pipeline definition and some of the pipeline steps that we built in the previous lessons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.steps.evaluator import evaluator\n",
    "from src.steps.importer import importer\n",
    "from src.pipelines.digits_pipeline import digits_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLFlow\n",
    "\n",
    "The only thing we need to change now to start using MLflow is the `svc_trainer` step. To do so, we define a new step `svc_trainer_mlflow` in which we use MLflow's `mlflow.sklearn.autolog()` feature to automatically log all relevant attributes of our model to MLflow. By adding an `@enable_mlflow` decorator on top of the function, ZenML then automatically initializes MLflow and takes care of the rest for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.svm import SVC\n",
    "import mlflow\n",
    "from zenml.integrations.mlflow.mlflow_step_decorator import enable_mlflow\n",
    "from zenml.steps import step, BaseStepConfig\n",
    "\n",
    "\n",
    "def build_svc_mlflow_pipeline(gamma=1e-3):\n",
    "    @enable_mlflow  # setup MLflow\n",
    "    @step(\n",
    "        enable_cache=False\n",
    "    )  # disable caching so we log **every** run to MLflow\n",
    "    def svc_trainer_mlflow(\n",
    "        X_train: np.ndarray,\n",
    "        y_train: np.ndarray,\n",
    "    ) -> ClassifierMixin:\n",
    "        \"\"\"Train a sklearn SVC classifier and log to MLflow.\"\"\"\n",
    "        mlflow.sklearn.autolog()  # log all model hparams and metrics to MLflow\n",
    "        model = SVC(gamma=gamma)\n",
    "        model.fit(X_train, y_train)\n",
    "        return model\n",
    "\n",
    "    return digits_pipeline(\n",
    "        importer=importer(),\n",
    "        trainer=svc_trainer_mlflow(),\n",
    "        evaluator=evaluator(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do the same for our decision tree trainer step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "def build_tree_mlflow_pipeline():\n",
    "    @enable_mlflow  # setup MLflow\n",
    "    @step(\n",
    "        enable_cache=False\n",
    "    )  # disable caching so we log **every** run to MLflow\n",
    "    def tree_trainer_with_mlflow(\n",
    "        X_train: np.ndarray,\n",
    "        y_train: np.ndarray,\n",
    "    ) -> ClassifierMixin:\n",
    "        \"\"\"Train a sklearn decision tree classifier and log to MLflow.\"\"\"\n",
    "        mlflow.sklearn.autolog()  # log all model hparams and metrics to MLflow\n",
    "        model = DecisionTreeClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "        return model\n",
    "\n",
    "    return digits_pipeline(\n",
    "        importer=importer(),\n",
    "        trainer=tree_trainer_with_mlflow(),\n",
    "        evaluator=evaluator(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to run our MLflow pipelines with ZenML, we first need to add MLflow into our MLOps stack.\n",
    "To do so, we first register a new experiment tracker with ZenML and then add it into our current stack.\n",
    "We can use `zenml stack describe` to show an overview of our currently active MLOps stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the MLflow experiment tracker\n",
    "!zenml experiment-tracker register mlflow_tracker --type=mlflow\n",
    "\n",
    "# Add the MLflow experiment tracker into our default stack\n",
    "!zenml stack update default -e mlflow_tracker\n",
    "\n",
    "# See an overview of your current MLOps stack\n",
    "!zenml stack describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're all setup so we can simply call `pipeline.run()` for all of our pipelines, which will now automatially log all of our pipeline runs to MLflow. Let's try it out and do a few pipeline runs with different hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_pipeline_svc_mlflow.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gamma in (1e-4, 1e-3, 1e-2, 1e-1):\n",
    "    config = SVCTrainerConfig(gamma=gamma)\n",
    "    digits_pipeline_svc_mlflow.with_config(config).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_pipeline_tree_mlflow.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare all of our runs within the MLflow UI, run the following cell, then open http://127.0.0.1:4997/ in your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will start a serving process for mlflow\n",
    "#  - if you want to continue in the notebook you need to manually\n",
    "#  interrupt the kernel\n",
    "from zenml.integrations.mlflow.mlflow_utils import get_tracking_uri\n",
    "\n",
    "!mlflow ui --backend-store-uri=\"{get_tracking_uri()}\" --port=4997"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights & Biases\n",
    "\n",
    "To get this example running, you need to set up a Weights & Biases account. You can do this for free [here](https://wandb.ai/login?signup=true)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the W&B experiment tracker\n",
    "!zenml experiment-tracker register wandb_tracker --type=wandb --api_key=<WANDB_API_KEY> --entity=<WANDB_ENTITY> --project_name=<WANDB_PROJECT_NAME>\n",
    "\n",
    "# Create a new stack with W&B experiment tracker in it\n",
    "!zenml stack register wandb_stack -m default -a default -o default -e wandb_tracker\n",
    "\n",
    "# Set it as the active stack\n",
    "!zenml stack set wandb_stack\n",
    "\n",
    "# See an overview of your current MLOps stack\n",
    "!zenml stack describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that despite wandb being used in different steps within a pipeline, ZenML handles initializing wandb and ensures the experiment name is the same as the pipeline name, and the experiment run is the same name as the pipeline run name. This establishes a lineage between pipelines in ZenML and experiments in wandb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import wandb\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.base import ClassifierMixin\n",
    "from zenml.integrations.wandb.wandb_step_decorator import enable_wandb\n",
    "from zenml.steps import step\n",
    "\n",
    "\n",
    "@enable_wandb(wandb.Settings(magic=True))\n",
    "@step\n",
    "@step(enable_cache=False)\n",
    "def svc_trainer_wandb(\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    ") -> ClassifierMixin:\n",
    "    \"\"\"Train another simple sklearn classifier for the digits dataset.\"\"\"\n",
    "    wandb.log()  # TODO\n",
    "    model = SVC(gamma=0.001)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9f70ec6e6bd16014ded89c8222361cbe53cd9507d51ebdcdf3ab6e494d45cf74"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('zenbytes')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
